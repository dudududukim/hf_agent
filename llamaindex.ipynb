{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe4f8b8",
   "metadata": {},
   "source": [
    "# basic import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a714338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kimduhyeon/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/kimduhyeon/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve HF_TOKEN from the environment variables\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "llm = HuggingFaceInferenceAPI(\n",
    "    model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=100,\n",
    "    token=hf_token,\n",
    "    provider=\"auto\"\n",
    ")\n",
    "\n",
    "response = llm.complete(\"Hello, how are you?\")\n",
    "print(response)\n",
    "# I am good, how can I help you today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e855a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 13:58:17,722 - WARNING - Ignoring wrong pointing object 12 0 (offset 0)\n",
      "2025-10-16 13:58:17,723 - WARNING - Ignoring wrong pointing object 30 0 (offset 0)\n",
      "2025-10-16 13:58:17,724 - WARNING - Ignoring wrong pointing object 31 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id_='200db532-a575-4b85-8f9b-5aa513d50c0b', embedding=None, metadata={'page_label': '1', 'file_name': 'Duhyeon_CV._oct09pdf.pdf', 'file_path': '/Users/kimduhyeon/Downloads/Duhyeon_CV._oct09pdf.pdf', 'file_type': 'application/pdf', 'file_size': 404671, 'creation_date': '2025-10-09', 'last_modified_date': '2025-10-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='DUHYEON  KIM  (‡¥Ö) \\n \\nProÔ¨Åle \\nEngineer with expertise in HDL-based hardware design and AI/system architecture. \\nExperienced in bridging low-level hardware optimization with high-level AI \\napplications to deliver impactful, efÔ¨Åcient solutions. \\nEducation \\nKorea University, Seoul, South Korea \\nüéì  M.S., Semiconductor System Engineering, Mar 2026 - Expected Feb 2028 \\nüéì  B.S., Electrical Engineering, Mar 2019 - Aug 2025 \\n‚Ä¢ GPA 4.05/4.5 \\nRelevant Coursework \\n‚Ä¢ Hardware Design - Digital System Design(A+), Digital Integrated Circuits(A+), \\nVLSI Design and Laboratory(A+), Data Structure and Algorithm(A+) \\n‚Ä¢ AI/ML - Advanced Machine Learning(A), Natural Language Processing(A+), \\nDigital Image Processing(A+), Computer Vision(A) \\nExperience \\nKAIST, ICLab - (Jul ~ Aug) 2025 \\nResearch Intern \\n‚Ä¢ Thesis : Real-time Voice-based AI Counseling Bot, Comparing three types of \\nvoice agent methodology \\n‚Ä¢ Open Source Contributions : \\n1) openai-agents-python: Voice transcription bug Ô¨Åx (PR #1537 merged) \\n2) openai-agents-js: Realtime API status bug report (Issue #336 resolved) \\nProjects \\nHardware Design \\n‚Ä¢ 32√ó32 Matrix Multiplier with parallel 4-MAC \\n: featuring counter-based addressing, 2-stage pipelining, and SRAM-based memory management \\n‚Ä¢ 2D-DCT Hardware for JPEG Compression \\n: Area-optimized design using TP-MEM merging, coefÔ¨Åcient symmetry, and custom DFT basis \\nmodiÔ¨Åcations. \\n‚Ä¢ Weight-Stationary Systolic Array \\n: comparison with adder-tree multiplier; analyzing resource utilization, timing, and scalability for varying \\nmatrix sizes \\n of 1 2\\n+82 10-6654-9551 \\nkdhluck@naver.com \\ndudududukim.github.io \\nSouth Korea \\nSeoul \\n119, Gireum-ro\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'), Document(id_='bf6b97ab-89ca-4c2b-9b91-08cbfa5be4ba', embedding=None, metadata={'page_label': '2', 'file_name': 'Duhyeon_CV._oct09pdf.pdf', 'file_path': '/Users/kimduhyeon/Downloads/Duhyeon_CV._oct09pdf.pdf', 'file_type': 'application/pdf', 'file_size': 404671, 'creation_date': '2025-10-09', 'last_modified_date': '2025-10-09'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='‚Ä¢ 5-Stage Pipelined RISC-V Processor \\n: with hazard detection, data forwarding, extending single-cycle architecture. \\nAI Applications \\n‚Ä¢ BERT-based Music Recommendation \\n: Fine-tuned klue/bert-base for Korean lyrics sentiment analysis \\n‚Ä¢ Generative Models (VAE, C-VAE, Info-GAN, Diffusion) \\n: PyTorch implementation of VAE, C-VAE, InfoGAN, and Diffusion models. \\n‚Ä¢ PyTorch Seminar Host \\n: covering training code structures and Neural Style Transfer. \\nHW‚ÄìSW Optimization \\n‚Ä¢ Compiler Extension for RISC-V \\n: Added IMAD instruction in LLVM/GCC for optimized 1D convolution performance. \\n‚Ä¢ Matrix Multiplication Optimization \\n: Loop tiling, SIMD, OpenMP achieving\\xa017√ó performance improvement\\xa0on Raspberry Pi 4B. \\nEmbedded Systems \\n‚Ä¢ Maze-Solving Robot using MOSFET Logic Gates \\n: Hardware-only navigation using 2N7000 logic gates, fastest completion time. \\n‚Ä¢ Smart Shared Refrigerator \\n: Raspberry Pi 4B system with OpenCV inventory tracking and 3-axis robotic placement. \\n‚Ä¢ Dog Tracking System on Jetson Nano \\n: Jetson Nano with CenterNet, TensorRT acceleration, and PID servo control. \\nSkills (Familiar with) \\nProgramming - C, Python, (System)Verilog, Matlab, PyTorch \\nEDA tools - Xilinx Vivado, Intel Quartus, Synopsys Design Compiler \\nSimulation and VeriÔ¨Åcation - Icarus Verilog (iverilog), GTKWave \\nScripting and Automation - Bash Shell \\nExternal Activities and Learning \\nCUDA Optimization for Single and Multi-GPU Performance - Jul 2024 \\nAI Engineer Fundamentals Online Course - Jan 2024 ‚Äì Feb 2024 \\nData Science Projects Coaching Study - Jan 2024 ‚Äì Feb 2024 \\n2024 MCL Winter Internship - Feb 2024 \\nLanguage \\nKorean(Native), English(OPIc IH / TEPS 432)\\n of 2 2', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "pdf_path = '/Users/kimduhyeon/Downloads/Duhyeon_CV._oct09pdf.pdf'\n",
    "reader = SimpleDirectoryReader(input_files=[pdf_path])\n",
    "documents = reader.load_data()\n",
    "\n",
    "print(documents[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d3ae0",
   "metadata": {},
   "source": [
    "# pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a575401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted text: DUHYEON KIM (ÍπÄÎëêÌòÑ) \n",
      " \n",
      "Profile \n",
      "Engineer with expertise in HDL-based hardware design and AI/system architecture. \n",
      "Experienced in bridging low-level hardware optimization with high-level AI \n",
      "applications to deliver impactful, efficient solutions. \n",
      "Education \n",
      "Korea University, Seoul, South Korea \n",
      "üéì M.S., Semiconductor System Engineering, Mar 2026 - Expected Feb 2028 \n",
      "üéì B.S., Electrical Engineering, Mar 2019 - Aug 2025 \n",
      "‚Ä¢ GPA 4.05/4.5 \n",
      "Relevant Coursework \n",
      "‚Ä¢ Hardware Design - Digital System Design(A+\n",
      "[Document(id_='24dfa4b4-3bae-4a4f-887f-3f8089611d8d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='DUHYEON KIM (ÍπÄÎëêÌòÑ) \\n \\nProfile \\nEngineer with expertise in HDL-based hardware design and AI/system architecture. \\nExperienced in bridging low-level hardware optimization with high-level AI \\napplications to deliver impactful, efficient solutions. \\nEducation \\nKorea University, Seoul, South Korea \\nüéì M.S., Semiconductor System Engineering, Mar 2026 - Expected Feb 2028 \\nüéì B.S., Electrical Engineering, Mar 2019 - Aug 2025 \\n‚Ä¢ GPA 4.05/4.5 \\nRelevant Coursework \\n‚Ä¢ Hardware Design - Digital System Design(A+), Digital Integrated Circuits(A+), \\nVLSI Design and Laboratory(A+), Data Structure and Algorithm(A+) \\n‚Ä¢ AI/ML - Advanced Machine Learning(A), Natural Language Processing(A+), \\nDigital Image Processing(A+), Computer Vision(A) \\nExperience \\nKAIST, ICLab - (Jul ~ Aug) 2025 \\nResearch Intern \\n‚Ä¢ Thesis : Real-time Voice-based AI Counseling Bot, Comparing three types of \\nvoice agent methodology \\n‚Ä¢ Open Source Contributions : \\n1) openai-agents-python: Voice transcription bug fix (PR #1537 merged) \\n2) openai-agents-js: Realtime API status bug report (Issue #336 resolved) \\nProjects \\nHardware Design \\n‚Ä¢ 32√ó32 Matrix Multiplier with parallel 4-MAC \\n: featuring counter-based addressing, 2-stage pipelining, and SRAM-based memory management \\n‚Ä¢ 2D-DCT Hardware for JPEG Compression \\n: Area-optimized design using TP-MEM merging, coefficient symmetry, and custom DFT basis \\nmodifications. \\n‚Ä¢ Weight-Stationary Systolic Array \\n: comparison with adder-tree multiplier; analyzing resource utilization, timing, and scalability for varying \\nmatrix sizes \\n of \\n1\\n2\\n+82 10-6654-9551 \\nkdhluck@naver.com \\ndudududukim.github.io \\nSouth Korea \\nSeoul \\n119, Gireum-ro\\n‚Ä¢ 5-Stage Pipelined RISC-V Processor \\n: with hazard detection, data forwarding, extending single-cycle architecture. \\nAI Applications \\n‚Ä¢ BERT-based Music Recommendation \\n: Fine-tuned klue/bert-base for Korean lyrics sentiment analysis \\n‚Ä¢ Generative Models (VAE, C-VAE, Info-GAN, Diffusion) \\n: PyTorch implementation of VAE, C-VAE, InfoGAN, and Diffusion models. \\n‚Ä¢ PyTorch Seminar Host \\n: covering training code structures and Neural Style Transfer. \\nHW‚ÄìSW Optimization \\n‚Ä¢ Compiler Extension for RISC-V \\n: Added IMAD instruction in LLVM/GCC for optimized 1D convolution performance. \\n‚Ä¢ Matrix Multiplication Optimization \\n: Loop tiling, SIMD, OpenMP achieving\\xa017√ó performance improvement\\xa0on Raspberry Pi 4B. \\nEmbedded Systems \\n‚Ä¢ Maze-Solving Robot using MOSFET Logic Gates \\n: Hardware-only navigation using 2N7000 logic gates, fastest completion time. \\n‚Ä¢ Smart Shared Refrigerator \\n: Raspberry Pi 4B system with OpenCV inventory tracking and 3-axis robotic placement. \\n‚Ä¢ Dog Tracking System on Jetson Nano \\n: Jetson Nano with CenterNet, TensorRT acceleration, and PID servo control. \\nSkills (Familiar with) \\nProgramming - C, Python, (System)Verilog, Matlab, PyTorch \\nEDA tools - Xilinx Vivado, Intel Quartus, Synopsys Design Compiler \\nSimulation and Verification - Icarus Verilog (iverilog), GTKWave \\nScripting and Automation - Bash Shell \\nExternal Activities and Learning \\nCUDA Optimization for Single and Multi-GPU Performance - Jul 2024 \\nAI Engineer Fundamentals Online Course - Jan 2024 ‚Äì Feb 2024 \\nData Science Projects Coaching Study - Jan 2024 ‚Äì Feb 2024 \\n2024 MCL Winter Internship - Feb 2024 \\nLanguage \\nKorean(Native), English(OPIc IH / TEPS 432)\\n of \\n2\\n2\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from llama_index.core import Document\n",
    "\n",
    "# PDF open\n",
    "doc = fitz.open('/Users/kimduhyeon/Downloads/Duhyeon_CV._oct09pdf.pdf')\n",
    "\n",
    "# text extract\n",
    "full_text = \"\"\n",
    "for page in doc:\n",
    "    full_text += page.get_text()\n",
    "\n",
    "# LlamaIndex Document\n",
    "documents = [Document(text=full_text)]\n",
    "\n",
    "print(f\"extracted text: {full_text[:500]}\")\n",
    "print(documents[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e35946",
   "metadata": {},
   "source": [
    "# chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0316d6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 13:58:24,262 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2025-10-16 13:58:27,666 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "# create the pipeline with transformations\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_overlap=0, chunk_size=256),\n",
    "        HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# nodes = await pipeline.arun(documents=[Document.example()])\n",
    "nodes = await pipeline.arun(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a4943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: DUHYEON KIM (ÍπÄÎëêÌòÑ) \n",
      " \n",
      "Profile \n",
      "Engineer with expertise in HDL-based hardware design and AI/system arc\n",
      "Embedding Dimension: 384\n",
      "Embedding Sample: [-0.07480106502771378, 0.04825197532773018, 0.058346476405858994, -0.07109431177377701, 0.04105697199702263, -0.02796272002160549, -0.0050787730142474174, 0.03678007796406746, -0.030957909300923347, -0.036979757249355316, 0.0470576174557209, -0.0528317391872406, 0.06541488319635391, -0.02232913114130497, 0.030958550050854683, -0.019247766584157944, -0.03825705498456955, 0.004458132199943066, 0.06012910231947899, -0.007345608435571194, 0.015679555013775826, -0.047658734023571014, -0.06091010570526123, -0.049731191247701645, -0.017749156802892685, -0.0427025742828846, 0.06439231336116791, -0.05228588357567787, -0.01951979473233223, -0.14514243602752686, 0.03283509239554405, 0.05806897208094597, 0.027195489034056664, 0.026477361097931862, -0.04303948953747749, 0.001907501369714737, 0.010908858850598335, 0.04465324804186821, -0.015882398933172226, -0.017287181690335274, -0.05810120329260826, -0.06218229979276657, 0.017537470906972885, -0.05291830748319626, 0.07941126823425293, -0.0025040102191269398, -0.03622660040855408, -0.06735818833112717, -0.053594835102558136, -0.052845362573862076, -0.015724128112196922, -0.018031008541584015, 0.0797336995601654, 0.045077066868543625, -0.02671133726835251, 0.009133555926382542, 0.06921615451574326, 0.03456372022628784, 0.06527639925479889, -0.01975776068866253, -0.01353458035737276, 0.012575767934322357, -0.1432655155658722, 0.04487667605280876, -0.03920993208885193, 0.04594999551773071, 0.008391101844608784, -0.08239366114139557, -0.005352264270186424, 0.04535984620451927, 0.039668019860982895, -0.005201784893870354, 0.025177445262670517, 0.03000609390437603, -0.0027176842559129, 0.020864393562078476, 0.03767184913158417, -0.04049019515514374, 0.01731458306312561, 0.039105840027332306, 0.04960692673921585, -0.04833897575736046, 0.013937227427959442, 0.007215939462184906, -0.023226028308272362, 0.0419742651283741, -0.00010484901577001438, 0.003394276136532426, -0.019433030858635902, -0.015488594770431519, 0.03947167471051216, 0.024669485166668892, -0.017538942396640778, -0.0020381584763526917, -0.014704208821058273, 0.026641804724931717, -0.06617868691682816, -0.057279542088508606, -0.03719380870461464, 0.3944321870803833, -0.026469504460692406, -0.003103179857134819, -0.0005788102280348539, -0.011893263086676598, 0.035368651151657104, -0.04888869822025299, -0.05288756266236305, -0.007121310103684664, -0.07263312488794327, -0.05161122977733612, -0.05241341516375542, 0.006376820150762796, 0.025749336928129196, 0.027175571769475937, 0.03696472570300102, 0.007510313764214516, -0.031193407252430916, 0.0009301968384534121, 0.0371873565018177, -0.04938075318932533, -0.013662165962159634, 0.03531157225370407, 0.010483641177415848, -0.049069225788116455, 0.0018577465089038014, -0.01593073271214962, -0.04467039555311203, 0.052688732743263245, 0.012171207927167416, 0.07795889675617218, 0.05794046074151993, -0.01010069064795971, -0.05787194147706032, 0.033150456845760345, 0.03265780955553055, 0.055889472365379333, -0.01554036047309637, 0.002175380941480398, -0.05210018530488014, -0.025784436613321304, -0.050822220742702484, 0.036380428820848465, 0.061645735055208206, -0.06276993453502655, -0.03447990491986275, 0.08077934384346008, -0.03209927678108215, 0.01572418585419655, 0.03141148388385773, 0.002319936640560627, 0.021398523822426796, -0.027827616780996323, 0.009255227632820606, -0.02552592009305954, 0.013840994797647, -0.013042057864367962, 0.006194176152348518, -0.009236042387783527, -0.06681905686855316, -0.008414126001298428, 0.012271005660295486, -0.027105111628770828, 0.011904191225767136, 0.09337394684553146, 0.01228194311261177, -0.0525679886341095, 0.029280027374625206, 0.05722369998693466, -0.00340713607147336, 0.007211856544017792, 0.02204766683280468, 0.06637997925281525, -0.012980609200894833, -0.016577579081058502, 0.01709907501935959, -0.014227848500013351, -0.02641482651233673, 0.0011517235543578863, -0.06240280345082283, -0.01932118833065033, -0.005816606339067221, 0.00798465870320797, 0.0237351655960083, -0.039821214973926544, 0.040274057537317276, -0.019669191911816597, 0.057502876967191696, 0.016345728188753128, 0.02077760361135006, 0.042085833847522736, -0.06271132081747055, 0.1108667328953743, 0.023451518267393112, -0.015733616426587105, 0.026621442288160324, -0.011448842473328114, -0.02284594625234604, -0.036644455045461655, -0.045099224895238876, -0.03726998716592789, 0.010334121063351631, 0.05913667380809784, -0.03667411580681801, -0.017513375729322433, -0.038283996284008026, -0.045029595494270325, 0.057167649269104004, -0.012028111144900322, -0.020533153787255287, 0.0336846262216568, -0.06359769403934479, 0.0037724380381405354, 0.007301409728825092, 0.004885828122496605, 0.04227546602487564, -0.01723487302660942, 0.01133914478123188, 0.018169373273849487, 0.0332101471722126, -0.008970921859145164, 0.0207065399736166, 0.008063411340117455, -0.03620879724621773, -0.3093959391117096, -0.006802237592637539, 0.04381787031888962, -0.06296902149915695, 0.018337488174438477, 0.02337929606437683, 0.02624918520450592, -0.0008208607905544341, 0.1001662090420723, 0.0037335758097469807, 0.050527047365903854, 0.013774371705949306, -0.006515312474220991, -0.05111686885356903, -0.025069689378142357, 0.0053096953779459, 0.08891355246305466, -0.02694748155772686, -0.03734665736556053, -0.06126517802476883, 0.04840392991900444, 0.03605349734425545, 0.04017190262675285, -0.05521329492330551, 0.029207058250904083, 0.024977514520287514, 0.06585618108510971, -0.07492119073867798, 0.04466940090060234, -0.0022612411994487047, -0.00915002916008234, -0.024094533175230026, 0.05347878858447075, -0.0377902053296566, 0.057326558977365494, 0.0017299214377999306, 0.04936704412102699, 0.0004965643747709692, 0.004514703527092934, -0.023376377299427986, -0.09632217139005661, 0.0650884285569191, -0.0441552959382534, -0.10164555162191391, -0.04986852407455444, -0.036265064030885696, 0.003449914511293173, -0.026065267622470856, -0.08467940986156464, 0.04126196727156639, -0.024568838998675346, -0.00878159049898386, 0.00123446190264076, 0.005178394727408886, 0.02086622454226017, 0.011408057995140553, -0.0743839368224144, 0.007774011231958866, -0.015504014678299427, 0.0383167564868927, 0.005714843515306711, -0.04225107282400131, -0.047432031482458115, 0.0045137666165828705, 0.013498121872544289, -0.029156330972909927, 0.014859182760119438, 0.04103744402527809, -0.02808012068271637, 0.009891967289149761, -0.030383462086319923, 0.06845307350158691, 0.0579526349902153, 0.00874276738613844, 0.1424078643321991, -0.009158347733318806, 0.019598182290792465, -0.12418923527002335, 0.029956871643662453, 0.06125123053789139, 0.06327416002750397, -0.0529465526342392, 0.03747598081827164, 0.003964689094573259, 0.030685773119330406, 0.04406476020812988, -0.014101754873991013, -0.03453189507126808, 0.00999641977250576, 0.027853792533278465, -0.05337684974074364, -0.050028376281261444, 0.012673933990299702, -0.036276038736104965, 0.04857570677995682, 0.0049368515610694885, -0.23953136801719666, 0.06085868924856186, 0.007874822244048119, 0.008898957632482052, -0.028425905853509903, -0.039259206503629684, -0.005294285248965025, -0.029319534078240395, -0.04292953386902809, -0.012646273709833622, -0.0647226944565773, 0.049015745520591736, 0.034914180636405945, 0.03481561318039894, -0.016888050362467766, -0.024986155331134796, 0.05297206714749336, -0.021131359040737152, 0.048121802508831024, 0.012078727595508099, 0.011902090162038803, 0.04202725738286972, 0.1443025767803192, 0.00025647925212979317, 0.03635918349027634, 0.004853119608014822, -0.03254547715187073, 0.009554801508784294, -0.04916674643754959, -0.024831296876072884, 0.006401919759809971, 0.009716106578707695, 0.048210617154836655, -0.01388788502663374, 0.010211091488599777, 0.09735990315675735, -0.0032799069304019213, -0.021866096183657646, -0.006669941358268261, 0.07234644144773483, 0.059973519295454025, -0.003460333216935396, -0.012102329172194004, 0.05179508775472641, 0.0968177542090416, 0.0575900599360466, -0.04793134704232216, -0.07350312918424606, -0.014914801344275475, 0.005473356228321791, -0.004209619946777821, -0.000940818979870528, -0.03528547286987305, -0.01744806207716465, -0.024021821096539497, 0.08855075389146805, -0.010913858190178871, -0.030219795182347298, 0.0032170608174055815, -0.08820564299821854, 0.026259619742631912, 0.0023151307832449675, 0.024086158722639084, 0.0591437891125679, -0.02015766128897667]\n",
      "ID: 1a838cab-10e0-437c-a5ef-391dc1cde9f7\n",
      "Metadata: {}\n"
     ]
    }
   ],
   "source": [
    "node = nodes[0]\n",
    "\n",
    "print(f\"Text: {node.text[:100]}\")\n",
    "print(f\"Embedding Dimension: {len(node.embedding)}\")\n",
    "print(f\"Embedding Sample: {node.embedding[:10]}\")\n",
    "print(f\"ID: {node.id_}\")\n",
    "print(f\"Metadata: {node.metadata}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e645e81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background-color: #FFE5E5; padding: 15px; margin: 10px 0; border-radius: 8px; border: 2px solid #FFE5CC;\">\n",
       "        <h3 style=\"color: #333; margin-top: 0;\">üìÑ Chunk #0</h3>\n",
       "        <pre style=\"white-space: pre-wrap; font-family: 'Courier New', monospace; color: #333;\">DUHYEON KIM (ÍπÄÎëêÌòÑ) \n",
       " \n",
       "Profile \n",
       "Engineer with expertise in HDL-based hardware design and AI/system architecture. \n",
       "Experienced in bridging low-level hardware optimization with high-level AI \n",
       "applications to deliver impactful, efficient solutions. \n",
       "Education \n",
       "Korea University, Seoul, South Korea \n",
       "üéì M.S., Semiconductor System Engineering, Mar 2026 - Expected Feb 2028 \n",
       "üéì B.S., Electrical Engineering, Mar 2019 - Aug 2025 \n",
       "‚Ä¢ GPA 4.05/4.5 \n",
       "Relevant Coursework \n",
       "‚Ä¢ Hardware Design - Digital System Design(A+), Digital Integrated Circuits(A+), \n",
       "VLSI Design and Laboratory(A+), Data Structure and Algorithm(A+) \n",
       "‚Ä¢ AI/ML - Advanced Machine Learning(A), Natural Language Processing(A+), \n",
       "Digital Image Processing(A+), Computer Vision(A) \n",
       "Experience \n",
       "KAIST, ICLab - (Jul ~ Aug) 2025 \n",
       "Research Intern \n",
       "‚Ä¢ Thesis : Real-time Voice-based AI Counseling Bot,</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background-color: #E5F5FF; padding: 15px; margin: 10px 0; border-radius: 8px; border: 2px solid #E5F5CC;\">\n",
       "        <h3 style=\"color: #333; margin-top: 0;\">üìÑ Chunk #1</h3>\n",
       "        <pre style=\"white-space: pre-wrap; font-family: 'Courier New', monospace; color: #333;\">Comparing three types of \n",
       "voice agent methodology \n",
       "‚Ä¢ Open Source Contributions : \n",
       "1) openai-agents-python: Voice transcription bug fix (PR #1537 merged) \n",
       "2) openai-agents-js: Realtime API status bug report (Issue #336 resolved) \n",
       "Projects \n",
       "Hardware Design \n",
       "‚Ä¢ 32√ó32 Matrix Multiplier with parallel 4-MAC \n",
       ": featuring counter-based addressing, 2-stage pipelining, and SRAM-based memory management \n",
       "‚Ä¢ 2D-DCT Hardware for JPEG Compression \n",
       ": Area-optimized design using TP-MEM merging, coefficient symmetry, and custom DFT basis \n",
       "modifications. \n",
       "‚Ä¢ Weight-Stationary Systolic Array \n",
       ": comparison with adder-tree multiplier; analyzing resource utilization, timing, and scalability for varying \n",
       "matrix sizes \n",
       " of \n",
       "1\n",
       "2\n",
       "+82 10-6654-9551 \n",
       "kdhluck@naver.com \n",
       "dudududukim.github.io \n",
       "South Korea \n",
       "Seoul \n",
       "119, Gireum-ro\n",
       "‚Ä¢ 5-Stage Pipelined RISC-V Processor \n",
       ": with hazard detection, data forwarding, extending single-cycle architecture.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background-color: #E5FFE5; padding: 15px; margin: 10px 0; border-radius: 8px; border: 2px solid #E5FFCC;\">\n",
       "        <h3 style=\"color: #333; margin-top: 0;\">üìÑ Chunk #2</h3>\n",
       "        <pre style=\"white-space: pre-wrap; font-family: 'Courier New', monospace; color: #333;\">AI Applications \n",
       "‚Ä¢ BERT-based Music Recommendation \n",
       ": Fine-tuned klue/bert-base for Korean lyrics sentiment analysis \n",
       "‚Ä¢ Generative Models (VAE, C-VAE, Info-GAN, Diffusion) \n",
       ": PyTorch implementation of VAE, C-VAE, InfoGAN, and Diffusion models. \n",
       "‚Ä¢ PyTorch Seminar Host \n",
       ": covering training code structures and Neural Style Transfer. \n",
       "HW‚ÄìSW Optimization \n",
       "‚Ä¢ Compiler Extension for RISC-V \n",
       ": Added IMAD instruction in LLVM/GCC for optimized 1D convolution performance. \n",
       "‚Ä¢ Matrix Multiplication Optimization \n",
       ": Loop tiling, SIMD, OpenMP achieving¬†17√ó performance improvement¬†on Raspberry Pi 4B. \n",
       "Embedded Systems \n",
       "‚Ä¢ Maze-Solving Robot using MOSFET Logic Gates \n",
       ": Hardware-only navigation using 2N7000 logic gates, fastest completion time. \n",
       "‚Ä¢ Smart Shared Refrigerator \n",
       ": Raspberry Pi 4B system with OpenCV inventory tracking and 3-axis robotic placement. \n",
       "‚Ä¢ Dog Tracking System on Jetson Nano \n",
       ": Jetson Nano with CenterNet, TensorRT acceleration, and PID servo control.</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"background-color: #FFF5E5; padding: 15px; margin: 10px 0; border-radius: 8px; border: 2px solid #FFF5CC;\">\n",
       "        <h3 style=\"color: #333; margin-top: 0;\">üìÑ Chunk #3</h3>\n",
       "        <pre style=\"white-space: pre-wrap; font-family: 'Courier New', monospace; color: #333;\">Skills (Familiar with) \n",
       "Programming - C, Python, (System)Verilog, Matlab, PyTorch \n",
       "EDA tools - Xilinx Vivado, Intel Quartus, Synopsys Design Compiler \n",
       "Simulation and Verification - Icarus Verilog (iverilog), GTKWave \n",
       "Scripting and Automation - Bash Shell \n",
       "External Activities and Learning \n",
       "CUDA Optimization for Single and Multi-GPU Performance - Jul 2024 \n",
       "AI Engineer Fundamentals Online Course - Jan 2024 ‚Äì Feb 2024 \n",
       "Data Science Projects Coaching Study - Jan 2024 ‚Äì Feb 2024 \n",
       "2024 MCL Winter Internship - Feb 2024 \n",
       "Language \n",
       "Korean(Native), English(OPIc IH / TEPS 432)\n",
       " of \n",
       "2\n",
       "2</pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# ÏÉâÏÉÅ ÌåîÎ†àÌä∏\n",
    "colors = ['#FFE5E5', '#E5F5FF', '#E5FFE5', '#FFF5E5', '#F5E5FF']\n",
    "\n",
    "# Í∞Å Ï≤≠ÌÅ¨Î•º ÏÉâÏÉÅÎ≥ÑÎ°ú Ï∂úÎ†•\n",
    "for i, node in enumerate(nodes):\n",
    "    color = colors[i % len(colors)]  # ÏÉâÏÉÅ ÏàúÌôò\n",
    "    html = f\"\"\"\n",
    "    <div style=\"background-color: {color}; padding: 15px; margin: 10px 0; border-radius: 8px; border: 2px solid {color[:-2]}CC;\">\n",
    "        <h3 style=\"color: #333; margin-top: 0;\">üìÑ Chunk #{i}</h3>\n",
    "        <pre style=\"white-space: pre-wrap; font-family: 'Courier New', monospace; color: #333;\">{node.text}</pre>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e00b11",
   "metadata": {},
   "source": [
    "# chromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fbda32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 13:58:29,865 - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "2025-10-16 13:58:30,226 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2025-10-16 13:58:33,054 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"./cv_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"cv_db\")        # easily the folder in DB\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(chunk_size=256, chunk_overlap=0),\n",
    "        HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "nodes = await pipeline.arun(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7e929",
   "metadata": {},
   "source": [
    "# indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cfbd239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 13:58:33,171 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2025-10-16 13:58:36,015 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e63ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=\"The meaning of life is a philosophical question that has been pondered by many throughout history. It involves exploring the purpose and significance of existence. While the skills and experiences mentioned suggest a focus on technology and engineering, these do not directly address the existential question of life's meaning. This is a deeply personal and subjective topic, often influenced by one's beliefs, values, and experiences.\", source_nodes=[NodeWithScore(node=TextNode(id_='d54ee6c6-40c5-49e4-b37b-06f5c8a03374', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='3a1881fd-4906-4c36-a48b-9d5a4257c360', node_type='4', metadata={}, hash='7d88fb7fae064b6f52eb39c83ddaadddd48878b0e57141c6e014da47759da497'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='24ae30e8-3cec-446d-8e25-67adcd43c5b4', node_type='1', metadata={}, hash='69e19f1401b6affec0b094131055a363d01176db3251cc3152a1e43785993d94')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Skills (Familiar with) \\nProgramming - C, Python, (System)Verilog, Matlab, PyTorch \\nEDA tools - Xilinx Vivado, Intel Quartus, Synopsys Design Compiler \\nSimulation and Verification - Icarus Verilog (iverilog), GTKWave \\nScripting and Automation - Bash Shell \\nExternal Activities and Learning \\nCUDA Optimization for Single and Multi-GPU Performance - Jul 2024 \\nAI Engineer Fundamentals Online Course - Jan 2024 ‚Äì Feb 2024 \\nData Science Projects Coaching Study - Jan 2024 ‚Äì Feb 2024 \\n2024 MCL Winter Internship - Feb 2024 \\nLanguage \\nKorean(Native), English(OPIc IH / TEPS 432)\\n of \\n2\\n2', mimetype='text/plain', start_char_idx=2730, end_char_idx=3310, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3226094413993001)], metadata={'d54ee6c6-40c5-49e4-b37b-06f5c8a03374': {}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\",provider=\"nscale\",)\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "query_engine.query(\"What is the meaning of life?\")\n",
    "# The meaning of life is 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38546781",
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "404 Client Error: Not Found for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-68f07b80-010713bd7158104e2afcb644;02ff663a-b0ed-4265-ae30-b5742cc202d5)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:407\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m llm = HuggingFaceInferenceAPI(model_name=\u001b[33m\"\u001b[39m\u001b[33mQwen/Qwen2.5-Coder-32B-Instruct\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m query_engine = index.as_query_engine(\n\u001b[32m      5\u001b[39m     llm=llm,\n\u001b[32m      6\u001b[39m     response_mode=\u001b[33m\"\u001b[39m\u001b[33mtree_summarize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mquery_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is the meaning of life?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# The meaning of life is 42\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index/core/base/base_query_engine.py:44\u001b[39m, in \u001b[36mBaseQueryEngine.query\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     43\u001b[39m         str_or_query_bundle = QueryBundle(str_or_query_bundle)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     query_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m dispatcher.event(\n\u001b[32m     46\u001b[39m     QueryEndEvent(query=str_or_query_bundle, response=query_result)\n\u001b[32m     47\u001b[39m )\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index/core/query_engine/retriever_query_engine.py:197\u001b[39m, in \u001b[36mRetrieverQueryEngine._query\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    194\u001b[39m     CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\n\u001b[32m    195\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[32m    196\u001b[39m     nodes = \u001b[38;5;28mself\u001b[39m.retrieve(query_bundle)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_response_synthesizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     query_event.on_end(payload={EventPayload.RESPONSE: response})\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index/core/response_synthesizers/base.py:235\u001b[39m, in \u001b[36mBaseSynthesizer.synthesize\u001b[39m\u001b[34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m     query = QueryBundle(query_str=query)\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._callback_manager.event(\n\u001b[32m    232\u001b[39m     CBEventType.SYNTHESIZE,\n\u001b[32m    233\u001b[39m     payload={EventPayload.QUERY_STR: query.query_str},\n\u001b[32m    234\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     response_str = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMetadataMode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m     additional_source_nodes = additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    244\u001b[39m     source_nodes = \u001b[38;5;28mlist\u001b[39m(nodes) + \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index/core/response_synthesizers/tree_summarize.py:159\u001b[39m, in \u001b[36mTreeSummarize.get_response\u001b[39m\u001b[34m(self, query_str, text_chunks, **response_kwargs)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._output_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m            \u001b[49m\u001b[43msummary_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontext_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    165\u001b[39m         response = \u001b[38;5;28mself\u001b[39m._llm.structured_predict(\n\u001b[32m    166\u001b[39m             \u001b[38;5;28mself\u001b[39m._output_cls,\n\u001b[32m    167\u001b[39m             summary_template,\n\u001b[32m    168\u001b[39m             context_str=text_chunks[\u001b[32m0\u001b[39m],\n\u001b[32m    169\u001b[39m             **response_kwargs,\n\u001b[32m    170\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index/core/llms/llm.py:623\u001b[39m, in \u001b[36mLLM.predict\u001b[39m\u001b[34m(self, prompt, **prompt_args)\u001b[39m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metadata.is_chat_model:\n\u001b[32m    622\u001b[39m     messages = \u001b[38;5;28mself\u001b[39m._get_messages(prompt, **prompt_args)\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m     chat_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m     output = chat_response.message.content \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index_instrumentation/dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/llama_index/llms/huggingface_api/base.py:287\u001b[39m, in \u001b[36mHuggingFaceInferenceAPI.chat\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.task == \u001b[33m\"\u001b[39m\u001b[33mconversational\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    285\u001b[39m     model_kwargs = \u001b[38;5;28mself\u001b[39m._get_model_kwargs(**kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     output: ChatCompletionOutput = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sync_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_huggingface_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     content = output.choices[\u001b[32m0\u001b[39m].message.content \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    293\u001b[39m     tool_calls = output.choices[\u001b[32m0\u001b[39m].message.tool_calls \u001b[38;5;129;01mor\u001b[39;00m []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:919\u001b[39m, in \u001b[36mInferenceClient.chat_completion\u001b[39m\u001b[34m(self, messages, model, stream, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream_options, temperature, tool_choice, tool_prompt, tools, top_logprobs, top_p, extra_body)\u001b[39m\n\u001b[32m    891\u001b[39m parameters = {\n\u001b[32m    892\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: payload_model,\n\u001b[32m    893\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   (...)\u001b[39m\u001b[32m    910\u001b[39m     **(extra_body \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    911\u001b[39m }\n\u001b[32m    912\u001b[39m request_parameters = provider_helper.prepare_request(\n\u001b[32m    913\u001b[39m     inputs=messages,\n\u001b[32m    914\u001b[39m     parameters=parameters,\n\u001b[32m   (...)\u001b[39m\u001b[32m    917\u001b[39m     api_key=\u001b[38;5;28mself\u001b[39m.token,\n\u001b[32m    918\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[32m    922\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _stream_chat_completion_response(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:275\u001b[39m, in \u001b[36mInferenceClient._inner_post\u001b[39m\u001b[34m(self, request_parameters, stream)\u001b[39m\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest_parameters.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.iter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response.content\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hf_ai_agent_course/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:480\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mHfHubHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://router.huggingface.co/hf-inference/models/Qwen/Qwen2.5-Coder-32B-Instruct/v1/chat/completions (Request ID: Root=1-68f07b80-010713bd7158104e2afcb644;02ff663a-b0ed-4265-ae30-b5742cc202d5)"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "query_engine.query(\"What is the meaning of life?\")\n",
    "# The meaning of life is 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cec637",
   "metadata": {},
   "source": [
    "# llama_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a84165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6343a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_agent",
   "language": "python",
   "name": "hf_agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
